{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Envis Insight Engine v2 \u2014 Improved Training\n",
    "\n",
    "Changes from v1 baseline:\n",
    "\n",
    "| Improvement | Rationale |\n",
    "|-------------|-----------|\n",
    "| **Unfreeze last 3 FinBERT layers** | v1 only trained 6.1% of params \u2014 adapters alone can't capture task-specific signal |\n",
    "| **Differential learning rate** | 1e-5 for BERT, 1e-4 for new heads \u2014 prevents catastrophic forgetting |\n",
    "| **Unified distress head (4-class)** | Sub-indicators never co-occur and only appear when distress=1 \u2192 single classification: none/self_blame/avoidance/secrecy |\n",
    "| **Log-transform timing delay** | Raw delay is heavily skewed (mean 142h, median 61h, std 153) \u2192 log1p reduces std to 1.19 |\n",
    "| **Class weights for framing** | 57.6% supportive vs 2.3% urgent \u2014 model predicts majority class without weights |\n",
    "| **Pos weights for binary tasks** | tension 30%, goal_risk 39% \u2014 rebalance gradients |\n",
    "| **Huber loss for delay** | Robust to remaining outliers after log transform |\n",
    "| **Cross-attention fusion** | Transaction\u2194text attention instead of simple gating |\n",
    "| **Mixed precision (fp16)** | ~2x faster on A100, no quality loss |\n",
    "| **Gradient accumulation** | Effective batch 32 from actual batch 16 |\n",
    "| **Reduced MAX_TEXT=128, MAX_TRANS=20** | p95 word count is 86, p95 transaction count is 18 \u2014 less padding waste |\n",
    "\n",
    "**Requirements:** Colab Pro with A100 GPU \u00b7 `financial_data_8k.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install -q transformers pandas scikit-learn tqdm tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import AutoModel, AutoTokenizer, get_cosine_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, f1_score,\n",
    "    mean_absolute_error, confusion_matrix, precision_recall_curve,\n",
    "    classification_report\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "import json, time, os, math\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional\n",
    "\n",
    "print(f\"PyTorch {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    try:\n",
    "        print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    except AttributeError:\n",
    "        print(\"(memory info not available in this PyTorch version)\")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()  # Select financial_data_8k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('financial_data_8k.csv')\n",
    "print(f\"Records: {len(df):,}  |  Columns: {len(df.columns)}\")\n",
    "\n",
    "# \u2500\u2500 Constants \u2500\u2500\n",
    "FRAMING_CLASSES = ['supportive', 'direct', 'celebratory', 'gentle', 'urgent']\n",
    "URGENCY_CLASSES = ['immediate', 'soon', 'can_wait']\n",
    "DISTRESS_CLASSES = ['none', 'self_blame', 'avoidance', 'secrecy']\n",
    "ROLE_TYPES      = ['partner_1', 'partner_2', 'child_1', 'child_2', 'child_3',\n",
    "                   'parent_1', 'parent_2', 'head_of_household', 'grandparent', 'other']\n",
    "AGE_BRACKETS    = ['18-25', '25-35', '35-45', '45-55', '55-65', '65+']\n",
    "INCOME_BRACKETS = ['low', 'medium', 'high', 'variable', 'unknown']\n",
    "\n",
    "# \u2500\u2500 Encode labels \u2500\u2500\n",
    "framing_to_idx = {f: i for i, f in enumerate(FRAMING_CLASSES)}\n",
    "urgency_to_idx = {u: i for i, u in enumerate(URGENCY_CLASSES)}\n",
    "df['framing_idx'] = df['framing'].map(framing_to_idx)\n",
    "df['urgency_idx'] = df['timing_urgency'].map(urgency_to_idx)\n",
    "\n",
    "# Unified distress class: sub-indicators never co-occur, only appear when distress=1\n",
    "# 0=none, 1=self_blame, 2=avoidance, 3=secrecy\n",
    "def encode_distress_class(row):\n",
    "    if row['self_blame'] == 1: return 1\n",
    "    if row['avoidance'] == 1:  return 2\n",
    "    if row['secrecy'] == 1:    return 3\n",
    "    return 0\n",
    "df['distress_class'] = df.apply(encode_distress_class, axis=1)\n",
    "\n",
    "# Log-transform timing delay\n",
    "df['timing_delay_log'] = np.log1p(df['timing_delay_hours'])\n",
    "\n",
    "# \u2500\u2500 Split \u2500\u2500\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['distress'])\n",
    "val_df, test_df   = train_test_split(temp_df, test_size=0.5, random_state=42, stratify=temp_df['distress'])\n",
    "print(f\"Train: {len(train_df):,}  Val: {len(val_df):,}  Test: {len(test_df):,}\")\n",
    "print(f\"\\nDistress classes: {df['distress_class'].value_counts().sort_index().to_dict()}\")\n",
    "print(f\"Framing: {df['framing'].value_counts().to_dict()}\")\n",
    "print(f\"Urgency: {df['timing_urgency'].value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(train_df)\n",
    "\n",
    "def inv_freq_weights(series, n_classes):\n",
    "    counts = series.value_counts().sort_index()\n",
    "    return torch.tensor([n / (n_classes * counts[i]) for i in range(n_classes)],\n",
    "                        dtype=torch.float, device=device)\n",
    "\n",
    "framing_w  = inv_freq_weights(train_df['framing_idx'], 5)\n",
    "urgency_w  = inv_freq_weights(train_df['urgency_idx'], 3)\n",
    "distress_w = inv_freq_weights(train_df['distress_class'], 4)\n",
    "\n",
    "print(\"Framing weights:  \", {FRAMING_CLASSES[i]: f\"{framing_w[i]:.2f}\" for i in range(5)})\n",
    "print(\"Urgency weights:  \", {URGENCY_CLASSES[i]: f\"{urgency_w[i]:.2f}\" for i in range(3)})\n",
    "print(\"Distress weights: \", {DISTRESS_CLASSES[i]: f\"{distress_w[i]:.2f}\" for i in range(4)})\n",
    "\n",
    "def pos_weight(col):\n",
    "    pos = train_df[col].sum()\n",
    "    return torch.tensor([n / pos - 1], dtype=torch.float, device=device)\n",
    "\n",
    "tension_pw   = pos_weight('tension')\n",
    "goal_risk_pw = pos_weight('goal_risk')\n",
    "print(f\"\\nTension pos_weight:   {tension_pw.item():.2f}\")\n",
    "print(f\"Goal-risk pos_weight: {goal_risk_pw.item():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset\n",
    "\n",
    "Reduced `MAX_TEXT=128` (p95 word count = 86) and `MAX_TRANS=20` (p95 = 18).\n",
    "Less padding \u2192 faster per-batch and lower memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('ProsusAI/finbert')\n",
    "\n",
    "MAX_TEXT    = 128\n",
    "MAX_TRANS   = 20\n",
    "MAX_MEMBERS = 5\n",
    "NODE_DIM    = len(ROLE_TYPES) + len(AGE_BRACKETS) + len(INCOME_BRACKETS)  # 21\n",
    "\n",
    "def parse_json(val):\n",
    "    return json.loads(val) if isinstance(val, str) else val\n",
    "\n",
    "def pad_seq(seq, max_len, pad=0):\n",
    "    seq = list(seq)[:max_len]\n",
    "    return seq + [pad] * (max_len - len(seq))\n",
    "\n",
    "def encode_nodes(roles, ages, incomes):\n",
    "    feats = []\n",
    "    for i in range(min(len(roles), MAX_MEMBERS)):\n",
    "        role_oh = [1.0 if roles[i] == r else 0.0 for r in ROLE_TYPES]\n",
    "        age_oh  = [1.0 if ages[i] == a else 0.0 for a in AGE_BRACKETS]\n",
    "        inc_oh  = [1.0 if incomes[i] == b else 0.0 for b in INCOME_BRACKETS]\n",
    "        feats.append(role_oh + age_oh + inc_oh)\n",
    "    while len(feats) < MAX_MEMBERS:\n",
    "        feats.append([0.0] * NODE_DIM)\n",
    "    return feats[:MAX_MEMBERS]\n",
    "\n",
    "def build_edges(edge_list, roles):\n",
    "    role_idx = {r: i for i, r in enumerate(roles[:MAX_MEMBERS])}\n",
    "    src, tgt = [], []\n",
    "    for edge in edge_list:\n",
    "        if len(edge) >= 2 and edge[0] in role_idx and edge[1] in role_idx:\n",
    "            s, t = role_idx[edge[0]], role_idx[edge[1]]\n",
    "            src.extend([s, t])\n",
    "            tgt.extend([t, s])\n",
    "    if not src:\n",
    "        return torch.zeros(2, 0, dtype=torch.long)\n",
    "    return torch.tensor([src, tgt], dtype=torch.long)\n",
    "\n",
    "\n",
    "class EnvisDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        enc = self.tokenizer(\n",
    "            row['text'], truncation=True, max_length=MAX_TEXT,\n",
    "            padding='max_length', return_tensors='pt'\n",
    "        )\n",
    "        amounts    = parse_json(row['transaction_amounts'])\n",
    "        categories = parse_json(row['transaction_categories'])\n",
    "        merchants  = parse_json(row['transaction_merchants'])\n",
    "        days       = parse_json(row['transaction_day_of_month'])\n",
    "        months     = parse_json(row['transaction_month'])\n",
    "        n_trans    = min(len(amounts), MAX_TRANS)\n",
    "        mask       = [1.0] * n_trans + [0.0] * (MAX_TRANS - n_trans)\n",
    "        roles   = parse_json(row['member_roles'])\n",
    "        ages    = parse_json(row['member_age_brackets'])\n",
    "        incomes = parse_json(row['member_income_brackets'])\n",
    "        edges   = parse_json(row['edge_list'])\n",
    "\n",
    "        return {\n",
    "            'input_ids':       enc['input_ids'].squeeze(),\n",
    "            'attention_mask':  enc['attention_mask'].squeeze(),\n",
    "            'amounts':         torch.tensor(pad_seq(amounts, MAX_TRANS), dtype=torch.float),\n",
    "            'categories':      torch.tensor(pad_seq(categories, MAX_TRANS), dtype=torch.long),\n",
    "            'merchants':       torch.tensor(pad_seq(merchants, MAX_TRANS), dtype=torch.long),\n",
    "            'days':            torch.tensor(pad_seq(days, MAX_TRANS, 1), dtype=torch.long),\n",
    "            'months':          torch.tensor(pad_seq(months, MAX_TRANS, 1), dtype=torch.long),\n",
    "            'trans_mask':      torch.tensor(mask[:MAX_TRANS], dtype=torch.float),\n",
    "            'node_features':   torch.tensor(encode_nodes(roles, ages, incomes), dtype=torch.float),\n",
    "            'edge_index':      build_edges(edges, roles),\n",
    "            'n_members':       torch.tensor(min(len(roles), MAX_MEMBERS), dtype=torch.long),\n",
    "            'distress_class':  torch.tensor(row['distress_class'], dtype=torch.long),\n",
    "            'distress_binary': torch.tensor(row['distress'], dtype=torch.float),\n",
    "            'framing':         torch.tensor(row['framing_idx'], dtype=torch.long),\n",
    "            'tension':         torch.tensor(row['tension'], dtype=torch.float),\n",
    "            'goal_risk':       torch.tensor(row['goal_risk'], dtype=torch.float),\n",
    "            'timing_delay':    torch.tensor(row['timing_delay_log'], dtype=torch.float),\n",
    "            'timing_urgency':  torch.tensor(row['urgency_idx'], dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    out = {}\n",
    "    for k in batch[0]:\n",
    "        out[k] = [b[k] for b in batch] if k == 'edge_index' else torch.stack([b[k] for b in batch])\n",
    "    return out\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "train_dataset = EnvisDataset(train_df, tokenizer)\n",
    "val_dataset   = EnvisDataset(val_df, tokenizer)\n",
    "test_dataset  = EnvisDataset(test_df, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True,  collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "val_loader   = DataLoader(val_dataset,   BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "test_loader  = DataLoader(test_dataset,  BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f\"Batches \u2014 Train: {len(train_loader)}  Val: {len(val_loader)}  Test: {len(test_loader)}\")\n",
    "s = train_dataset[0]\n",
    "print(\"\\nSample shapes:\")\n",
    "for k, v in s.items():\n",
    "    if isinstance(v, torch.Tensor): print(f\"  {k:20s} {str(v.shape):15s} {v.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model v2\n",
    "\n",
    "- **FinBERT layers 9\u201311 unfrozen** with lower LR\n",
    "- **Unified 4-class distress head** replaces separate binary distress + 3 sub-indicator heads\n",
    "- **Cross-attention fusion** \u2014 transaction\u2194text bidirectional attention before gating\n",
    "- **Residual prediction heads** for better gradient flow\n",
    "- **Raw logits** everywhere \u2014 loss functions handle sigmoid/softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    transaction_vocab_size: int = 8001\n",
    "    transaction_embedding_dim: int = 256\n",
    "    transaction_num_layers: int = 4\n",
    "    transaction_num_heads: int = 8\n",
    "    transaction_ff_dim: int = 1024\n",
    "    num_amount_buckets: int = 13\n",
    "    amount_embedding_dim: int = 32\n",
    "    num_categories: int = 120\n",
    "    category_embedding_dim: int = 64\n",
    "    text_model_name: str = 'ProsusAI/finbert'\n",
    "    text_embedding_dim: int = 768\n",
    "    adapter_dim: int = 64\n",
    "    unfreeze_layers: int = 3\n",
    "    node_feature_dim: int = NODE_DIM\n",
    "    household_hidden_dim: int = 64\n",
    "    household_num_layers: int = 3\n",
    "    household_num_heads: int = 4\n",
    "    fusion_dim: int = 512\n",
    "    dropout: float = 0.1\n",
    "    num_distress_classes: int = 4\n",
    "    num_framing_classes: int = 5\n",
    "    num_urgency_classes: int = 3\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Amount Encoder (log-scale buckets) \u2500\u2500\u2500\n",
    "\n",
    "class AmountEncoder(nn.Module):\n",
    "    BOUNDS = [0, 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000, 2000]\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(cfg.num_amount_buckets, cfg.amount_embedding_dim)\n",
    "    def forward(self, amounts):\n",
    "        buckets = torch.zeros_like(amounts, dtype=torch.long)\n",
    "        for i, b in enumerate(self.BOUNDS):\n",
    "            buckets = torch.where(amounts >= b, torch.tensor(i, device=amounts.device), buckets)\n",
    "        return self.emb(buckets.clamp(max=len(self.BOUNDS)))\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Temporal Encoder \u2500\u2500\u2500\n",
    "\n",
    "class TemporalEncoder(nn.Module):\n",
    "    def __init__(self, max_seq=MAX_TRANS, pos_dim=32):\n",
    "        super().__init__()\n",
    "        self.dom_emb   = nn.Embedding(32, 16)\n",
    "        self.month_emb = nn.Embedding(13, 16)\n",
    "        self.pos_emb   = nn.Embedding(max_seq, pos_dim)\n",
    "        self.out_dim   = 64\n",
    "\n",
    "    def forward(self, day_of_month, month, positions):\n",
    "        return torch.cat([\n",
    "            self.dom_emb(day_of_month), self.month_emb(month), self.pos_emb(positions)\n",
    "        ], dim=-1)\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Transaction Encoder (4-layer Transformer) \u2500\u2500\u2500\n",
    "\n",
    "class TransactionEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.amount_enc = AmountEncoder(cfg)\n",
    "        self.cat_emb    = nn.Embedding(cfg.num_categories, cfg.category_embedding_dim)\n",
    "        self.merch_emb  = nn.Embedding(cfg.transaction_vocab_size, cfg.category_embedding_dim)\n",
    "        self.temp_enc   = TemporalEncoder()\n",
    "        in_dim = cfg.amount_embedding_dim + cfg.category_embedding_dim * 2 + self.temp_enc.out_dim\n",
    "        self.input_proj = nn.Linear(in_dim, cfg.transaction_embedding_dim)\n",
    "        layer = nn.TransformerEncoderLayer(\n",
    "            d_model=cfg.transaction_embedding_dim, nhead=cfg.transaction_num_heads,\n",
    "            dim_feedforward=cfg.transaction_ff_dim, dropout=cfg.dropout, batch_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=cfg.transaction_num_layers)\n",
    "\n",
    "    def forward(self, amounts, categories, merchants, days, months, mask=None):\n",
    "        B, S = amounts.shape\n",
    "        pos = torch.arange(S, device=amounts.device).unsqueeze(0).expand(B, -1)\n",
    "        combined = torch.cat([\n",
    "            self.amount_enc(amounts), self.cat_emb(categories),\n",
    "            self.merch_emb(merchants), self.temp_enc(days, months, pos),\n",
    "        ], dim=-1)\n",
    "        projected = self.input_proj(combined)\n",
    "        pad_mask = ~mask.bool() if mask is not None else None\n",
    "        return self.transformer(projected, src_key_padding_mask=pad_mask)\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Adapter (Houlsby et al., 2019) \u2500\u2500\u2500\n",
    "\n",
    "class Adapter(nn.Module):\n",
    "    def __init__(self, dim, bottleneck):\n",
    "        super().__init__()\n",
    "        self.down = nn.Linear(dim, bottleneck)\n",
    "        self.up   = nn.Linear(bottleneck, dim)\n",
    "        self.act  = nn.GELU()\n",
    "    def forward(self, x):\n",
    "        return x + self.up(self.act(self.down(x)))\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Text Encoder (FinBERT, last 3 layers unfrozen + adapters) \u2500\u2500\u2500\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(cfg.text_model_name)\n",
    "        for p in self.bert.parameters():\n",
    "            p.requires_grad = False\n",
    "        n_layers = len(self.bert.encoder.layer)\n",
    "        for i in range(n_layers - cfg.unfreeze_layers, n_layers):\n",
    "            for p in self.bert.encoder.layer[i].parameters():\n",
    "                p.requires_grad = True\n",
    "        self.adapters = nn.ModuleList([\n",
    "            Adapter(cfg.text_embedding_dim, cfg.adapter_dim) for _ in range(n_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out = self.bert(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                        output_hidden_states=True)\n",
    "        cls = out.hidden_states[-1][:, 0, :]\n",
    "        for i, adapter in enumerate(self.adapters):\n",
    "            layer_cls = out.hidden_states[i + 1][:, 0, :]\n",
    "            cls = cls + 0.1 * adapter(layer_cls)\n",
    "        return cls, out.last_hidden_state\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 GAT Layer \u2500\u2500\u2500\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.heads, self.out_dim = heads, out_dim\n",
    "        self.W = nn.Linear(in_dim, out_dim * heads, bias=False)\n",
    "        self.a = nn.Parameter(torch.zeros(heads, 2 * out_dim))\n",
    "        nn.init.xavier_uniform_(self.a)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.W(x).view(-1, self.heads, self.out_dim)\n",
    "        if edge_index.shape[1] == 0:\n",
    "            return h.mean(dim=1)\n",
    "        src, tgt = edge_index\n",
    "        alpha = torch.cat([h[src], h[tgt]], dim=-1)\n",
    "        alpha = self.leaky_relu((alpha * self.a).sum(dim=-1))\n",
    "        alpha = self.dropout(F.softmax(alpha, dim=0))\n",
    "        out = torch.zeros_like(h)\n",
    "        out.index_add_(0, tgt, alpha.unsqueeze(-1) * h[src])\n",
    "        return out.mean(dim=1)\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Household Encoder (3-layer GAT) \u2500\u2500\u2500\n",
    "\n",
    "class HouseholdEncoder(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(cfg.node_feature_dim, cfg.household_hidden_dim)\n",
    "        self.layers = nn.ModuleList([\n",
    "            GATLayer(cfg.household_hidden_dim, cfg.household_hidden_dim,\n",
    "                     cfg.household_num_heads, cfg.dropout)\n",
    "            for _ in range(cfg.household_num_layers)\n",
    "        ])\n",
    "        self.pool_attn = nn.Linear(cfg.household_hidden_dim, 1)\n",
    "\n",
    "    def forward(self, node_features, edge_index, n_members):\n",
    "        x = self.input_proj(node_features[:n_members])\n",
    "        for layer in self.layers:\n",
    "            x = F.elu(layer(x, edge_index))\n",
    "        weights = F.softmax(self.pool_attn(x), dim=0)\n",
    "        return (weights * x).sum(dim=0)\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Cross-Attention Fusion \u2500\u2500\u2500\n",
    "\n",
    "class CrossAttentionFusion(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        d = cfg.fusion_dim\n",
    "        self.trans_proj = nn.Linear(cfg.transaction_embedding_dim, d)\n",
    "        self.text_proj  = nn.Linear(cfg.text_embedding_dim, d)\n",
    "        self.house_proj = nn.Linear(cfg.household_hidden_dim, d)\n",
    "        self.trans_text_attn = nn.MultiheadAttention(d, 8, dropout=cfg.dropout, batch_first=True)\n",
    "        self.text_house_attn = nn.MultiheadAttention(d, 4, dropout=cfg.dropout, batch_first=True)\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(d * 3, d), nn.ReLU(), nn.Dropout(cfg.dropout),\n",
    "            nn.Linear(d, 3), nn.Softmax(dim=-1),\n",
    "        )\n",
    "        self.out_proj = nn.Linear(d * 3, d)\n",
    "        self.norm = nn.LayerNorm(d)\n",
    "        self.drop = nn.Dropout(cfg.dropout)\n",
    "\n",
    "    def forward(self, trans_seq, text_cls, text_tokens, house_emb):\n",
    "        t_proj = self.trans_proj(trans_seq)\n",
    "        x_proj = self.text_proj(text_tokens)\n",
    "        x_cls  = self.text_proj(text_cls)\n",
    "        h      = self.house_proj(house_emb)\n",
    "\n",
    "        t_query = t_proj.mean(dim=1, keepdim=True)\n",
    "        t_cross, _ = self.trans_text_attn(t_query, x_proj, x_proj)\n",
    "        t_enh = t_query.squeeze(1) + t_cross.squeeze(1)\n",
    "\n",
    "        h_kv = h.unsqueeze(1)\n",
    "        x_cross, _ = self.text_house_attn(x_cls.unsqueeze(1), h_kv, h_kv)\n",
    "        x_enh = x_cls + x_cross.squeeze(1)\n",
    "\n",
    "        cat = torch.cat([t_enh, x_enh, h], dim=-1)\n",
    "        g = self.gate(cat)\n",
    "        gated = torch.cat([g[:,0:1]*t_enh, g[:,1:2]*x_enh, g[:,2:3]*h], dim=-1)\n",
    "        return self.norm(self.drop(self.out_proj(gated)))\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Residual Prediction Head \u2500\u2500\u2500\n",
    "\n",
    "class ResHead(nn.Module):\n",
    "    def __init__(self, in_d, out_d, hidden=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_d, hidden)\n",
    "        self.fc2 = nn.Linear(hidden, hidden)\n",
    "        self.fc3 = nn.Linear(hidden, out_d)\n",
    "        self.skip = nn.Linear(in_d, hidden) if in_d != hidden else nn.Identity()\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = self.drop(h)\n",
    "        h = F.relu(self.fc2(h) + self.skip(x))\n",
    "        h = self.drop(h)\n",
    "        return self.fc3(h)\n",
    "\n",
    "\n",
    "# \u2500\u2500\u2500 Envis v2 \u2500\u2500\u2500\n",
    "\n",
    "class EnvisV2(nn.Module):\n",
    "    def __init__(self, cfg=None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg or ModelConfig()\n",
    "        c = self.cfg\n",
    "        self.trans_enc  = TransactionEncoder(c)\n",
    "        self.text_enc   = TextEncoder(c)\n",
    "        self.house_enc  = HouseholdEncoder(c)\n",
    "        self.fusion     = CrossAttentionFusion(c)\n",
    "\n",
    "        self.distress_head  = ResHead(c.fusion_dim, c.num_distress_classes)\n",
    "        self.framing_head   = ResHead(c.fusion_dim, c.num_framing_classes)\n",
    "        self.urgency_head   = ResHead(c.fusion_dim, c.num_urgency_classes)\n",
    "        self.tension_head   = ResHead(c.fusion_dim, 1)\n",
    "        self.goal_risk_head = ResHead(c.fusion_dim, 1)\n",
    "        self.delay_head     = ResHead(c.fusion_dim, 1)\n",
    "        self.log_vars = nn.Parameter(torch.zeros(6))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        B = batch['input_ids'].shape[0]\n",
    "        trans_seq = self.trans_enc(\n",
    "            batch['amounts'], batch['categories'], batch['merchants'],\n",
    "            batch['days'], batch['months'], batch['trans_mask'],\n",
    "        )\n",
    "        text_cls, text_tokens = self.text_enc(batch['input_ids'], batch['attention_mask'])\n",
    "        house_list = []\n",
    "        for i in range(B):\n",
    "            h = self.house_enc(\n",
    "                batch['node_features'][i],\n",
    "                batch['edge_index'][i].to(batch['input_ids'].device),\n",
    "                batch['n_members'][i].item(),\n",
    "            )\n",
    "            house_list.append(h)\n",
    "        house_emb = torch.stack(house_list)\n",
    "        fused = self.fusion(trans_seq, text_cls, text_tokens, house_emb)\n",
    "\n",
    "        return {\n",
    "            'distress':       self.distress_head(fused),\n",
    "            'framing':        self.framing_head(fused),\n",
    "            'timing_urgency': self.urgency_head(fused),\n",
    "            'tension':        self.tension_head(fused).squeeze(-1),\n",
    "            'goal_risk':      self.goal_risk_head(fused).squeeze(-1),\n",
    "            'timing_delay':   self.delay_head(fused).squeeze(-1),\n",
    "            'log_vars':       self.log_vars,\n",
    "        }\n",
    "\n",
    "\n",
    "cfg = ModelConfig()\n",
    "model = EnvisV2(cfg).to(device)\n",
    "\n",
    "total     = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "bert_unfrozen = sum(p.numel() for n, p in model.text_enc.bert.named_parameters() if p.requires_grad)\n",
    "print(f\"Total parameters:     {total:,}\")\n",
    "print(f\"Trainable:            {trainable:,} ({100*trainable/total:.1f}%)\")\n",
    "print(f\"  BERT unfrozen:      {bert_unfrozen:,} (last {cfg.unfreeze_layers} layers)\")\n",
    "print(f\"  New components:     {trainable - bert_unfrozen:,}\")\n",
    "print(f\"Frozen:               {total - trainable:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loss & Evaluation\n",
    "\n",
    "- Weighted `CrossEntropyLoss` for distress 4-class, framing, urgency\n",
    "- `BCEWithLogitsLoss` with `pos_weight` for tension, goal_risk\n",
    "- `HuberLoss` for log-scale timing delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_distress = nn.CrossEntropyLoss(weight=distress_w)\n",
    "ce_framing  = nn.CrossEntropyLoss(weight=framing_w)\n",
    "ce_urgency  = nn.CrossEntropyLoss(weight=urgency_w)\n",
    "bce_tension = nn.BCEWithLogitsLoss(pos_weight=tension_pw)\n",
    "bce_goal    = nn.BCEWithLogitsLoss(pos_weight=goal_risk_pw)\n",
    "huber_delay = nn.HuberLoss(delta=1.0)\n",
    "\n",
    "\n",
    "def compute_loss(preds, batch):\n",
    "    lv = preds['log_vars']\n",
    "    losses = {\n",
    "        'distress':  ce_distress(preds['distress'], batch['distress_class']),\n",
    "        'framing':   ce_framing(preds['framing'], batch['framing']),\n",
    "        'urgency':   ce_urgency(preds['timing_urgency'], batch['timing_urgency']),\n",
    "        'tension':   bce_tension(preds['tension'], batch['tension']),\n",
    "        'goal_risk': bce_goal(preds['goal_risk'], batch['goal_risk']),\n",
    "        'delay':     huber_delay(preds['timing_delay'], batch['timing_delay']),\n",
    "    }\n",
    "    total = sum(torch.exp(-lv[i]) * v + lv[i] for i, v in enumerate(losses.values()))\n",
    "    return total, {k: v.item() for k, v in losses.items()}\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    keys = ['distress_class', 'distress_prob', 'framing', 'tension',\n",
    "            'goal_risk', 'timing_delay', 'timing_urgency']\n",
    "    P = {k: [] for k in keys}\n",
    "    L = {k: [] for k in keys}\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        b = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "        with autocast():\n",
    "            preds = model(b)\n",
    "            loss, _ = compute_loss(preds, b)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        d_probs = F.softmax(preds['distress'], dim=1)\n",
    "        P['distress_class'].extend(d_probs.argmax(1).cpu().numpy())\n",
    "        L['distress_class'].extend(batch['distress_class'].numpy())\n",
    "        P['distress_prob'].extend((1 - d_probs[:, 0]).cpu().numpy())\n",
    "        L['distress_prob'].extend(batch['distress_binary'].numpy())\n",
    "\n",
    "        P['framing'].extend(preds['framing'].argmax(1).cpu().numpy())\n",
    "        L['framing'].extend(batch['framing'].numpy())\n",
    "        P['timing_urgency'].extend(preds['timing_urgency'].argmax(1).cpu().numpy())\n",
    "        L['timing_urgency'].extend(batch['timing_urgency'].numpy())\n",
    "        P['tension'].extend(torch.sigmoid(preds['tension']).cpu().numpy())\n",
    "        L['tension'].extend(batch['tension'].numpy())\n",
    "        P['goal_risk'].extend(torch.sigmoid(preds['goal_risk']).cpu().numpy())\n",
    "        L['goal_risk'].extend(batch['goal_risk'].numpy())\n",
    "        P['timing_delay'].extend(torch.expm1(preds['timing_delay']).cpu().numpy())\n",
    "        L['timing_delay'].extend(torch.expm1(batch['timing_delay']).cpu().numpy())\n",
    "\n",
    "    m = {\n",
    "        'loss':              total_loss / len(loader),\n",
    "        'distress_auc':      roc_auc_score(L['distress_prob'], P['distress_prob']),\n",
    "        'distress_4cls_acc': accuracy_score(L['distress_class'], P['distress_class']),\n",
    "        'distress_4cls_f1':  f1_score(L['distress_class'], P['distress_class'], average='macro'),\n",
    "        'framing_acc':       accuracy_score(L['framing'], P['framing']),\n",
    "        'framing_f1':        f1_score(L['framing'], P['framing'], average='macro'),\n",
    "        'tension_auc':       roc_auc_score(L['tension'], P['tension']),\n",
    "        'goal_risk_auc':     roc_auc_score(L['goal_risk'], P['goal_risk']),\n",
    "        'delay_mae_hours':   mean_absolute_error(L['timing_delay'], P['timing_delay']),\n",
    "        'urgency_acc':       accuracy_score(L['timing_urgency'], P['timing_urgency']),\n",
    "    }\n",
    "    return m, P, L\n",
    "\n",
    "print(\"Loss and eval defined \u2713\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Training\n",
    "\n",
    "- **Differential LR**: BERT 1e-5, new components 1e-4\n",
    "- **Mixed precision** fp16\n",
    "- **Gradient accumulation** 2 steps \u2192 effective batch 32\n",
    "- **Early stopping** patience 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS       = 25\n",
    "LR_BERT      = 1e-5\n",
    "LR_NEW       = 1e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "WARMUP_STEPS = 500\n",
    "PATIENCE     = 5\n",
    "ACCUM_STEPS  = 2\n",
    "\n",
    "bert_ids = set(id(p) for p in model.text_enc.bert.parameters() if p.requires_grad)\n",
    "bert_params = [p for p in model.text_enc.bert.parameters() if p.requires_grad]\n",
    "new_params  = [p for p in model.parameters() if p.requires_grad and id(p) not in bert_ids]\n",
    "\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': bert_params, 'lr': LR_BERT},\n",
    "    {'params': new_params,  'lr': LR_NEW},\n",
    "], weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "total_steps = (len(train_loader) * EPOCHS) // ACCUM_STEPS\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, WARMUP_STEPS, total_steps)\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(f\"BERT trainable (lr={LR_BERT}): {sum(p.numel() for p in bert_params):,}\")\n",
    "print(f\"New params (lr={LR_NEW}):      {sum(p.numel() for p in new_params):,}\")\n",
    "print(f\"Effective batch size:           {BATCH_SIZE * ACCUM_STEPS}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_ctr  = 0\n",
    "training_log  = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    t0 = time.time()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    for step, batch in enumerate(pbar):\n",
    "        b = {k: (v.to(device) if isinstance(v, torch.Tensor) else v) for k, v in batch.items()}\n",
    "\n",
    "        with autocast():\n",
    "            preds = model(b)\n",
    "            loss, task_losses = compute_loss(preds, b)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            scheduler.step()\n",
    "\n",
    "        epoch_loss += loss.item() * ACCUM_STEPS\n",
    "        pbar.set_postfix(loss=f\"{loss.item()*ACCUM_STEPS:.4f}\")\n",
    "\n",
    "    epoch_time = time.time() - t0\n",
    "    val_m, _, _ = evaluate(model, val_loader)\n",
    "\n",
    "    entry = {\n",
    "        'epoch':            epoch + 1,\n",
    "        'train_loss':       round(epoch_loss / len(train_loader), 4),\n",
    "        'val_loss':         round(val_m['loss'], 4),\n",
    "        'distress_auc':     round(val_m['distress_auc'], 4),\n",
    "        'distress_4cls_f1': round(val_m['distress_4cls_f1'], 4),\n",
    "        'framing_acc':      round(val_m['framing_acc'], 4),\n",
    "        'framing_f1':       round(val_m['framing_f1'], 4),\n",
    "        'tension_auc':      round(val_m['tension_auc'], 4),\n",
    "        'goal_risk_auc':    round(val_m['goal_risk_auc'], 4),\n",
    "        'delay_mae':        round(val_m['delay_mae_hours'], 1),\n",
    "        'urgency_acc':      round(val_m['urgency_acc'], 4),\n",
    "        'time_sec':         round(epoch_time, 1),\n",
    "    }\n",
    "    training_log.append(entry)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}: train={entry['train_loss']:.4f} val={entry['val_loss']:.4f} \"\n",
    "          f\"d_auc={entry['distress_auc']:.4f} d4_f1={entry['distress_4cls_f1']:.4f} \"\n",
    "          f\"f_acc={entry['framing_acc']:.4f} f_f1={entry['framing_f1']:.4f}\")\n",
    "    print(f\"  t_auc={entry['tension_auc']:.4f} gr_auc={entry['goal_risk_auc']:.4f} \"\n",
    "          f\"delay={entry['delay_mae']:.1f}h urg_acc={entry['urgency_acc']:.4f} \"\n",
    "          f\"time={epoch_time:.0f}s\")\n",
    "\n",
    "    if val_m['loss'] < best_val_loss:\n",
    "        best_val_loss = val_m['loss']\n",
    "        patience_ctr = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': val_m['loss'],\n",
    "            'val_metrics': val_m,\n",
    "            'config': cfg.__dict__,\n",
    "        }, 'best_model_v2.pt')\n",
    "        print(\"  \u2713 Best model saved\")\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        print(f\"  No improvement ({patience_ctr}/{PATIENCE})\")\n",
    "\n",
    "    if patience_ctr >= PATIENCE:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('best_model_v2.pt', weights_only=False)\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {ckpt['epoch']} (val_loss={ckpt['val_loss']:.4f})\")\n",
    "\n",
    "test_m, test_P, test_L = evaluate(model, test_loader)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEST RESULTS \u2014 v2\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"  Distress AUC (binary):     {test_m['distress_auc']:.4f}\")\n",
    "print(f\"  Distress 4-class Acc:      {test_m['distress_4cls_acc']:.4f}\")\n",
    "print(f\"  Distress 4-class F1:       {test_m['distress_4cls_f1']:.4f}\")\n",
    "print(f\"  Framing Accuracy:          {test_m['framing_acc']:.4f}\")\n",
    "print(f\"  Framing F1 (macro):        {test_m['framing_f1']:.4f}\")\n",
    "print(f\"  Tension AUC:               {test_m['tension_auc']:.4f}\")\n",
    "print(f\"  Goal-Risk AUC:             {test_m['goal_risk_auc']:.4f}\")\n",
    "print(f\"  Timing Delay MAE:          {test_m['delay_mae_hours']:.1f} hours\")\n",
    "print(f\"  Timing Urgency Acc:        {test_m['urgency_acc']:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Distress 4-class report ---\")\n",
    "print(classification_report(\n",
    "    test_L['distress_class'], test_P['distress_class'],\n",
    "    target_names=['none', 'self_blame', 'avoidance', 'secrecy']\n",
    "))\n",
    "\n",
    "print(\"--- Framing report ---\")\n",
    "print(classification_report(\n",
    "    test_L['framing'], test_P['framing'],\n",
    "    target_names=FRAMING_CLASSES\n",
    "))\n",
    "\n",
    "# Binary distress threshold\n",
    "prec, rec, thr = precision_recall_curve(test_L['distress_prob'], test_P['distress_prob'])\n",
    "f1s = 2 * prec * rec / (prec + rec + 1e-8)\n",
    "best_thr = float(thr[np.argmax(f1s)])\n",
    "print(f\"Binary distress threshold: {best_thr:.3f}, best F1: {np.max(f1s):.3f}\")\n",
    "\n",
    "d_bin_pred = (np.array(test_P['distress_prob']) >= best_thr).astype(int)\n",
    "d_bin_true = np.array(test_L['distress_prob']).astype(int)\n",
    "print(\"\\nDistress binary confusion matrix:\")\n",
    "print(confusion_matrix(d_bin_true, d_bin_pred))\n",
    "print(\"\\nFraming confusion matrix:\")\n",
    "print(confusion_matrix(test_L['framing'], test_P['framing']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save & Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(training_log)\n",
    "log_df.to_csv('training_log_v2.csv', index=False)\n",
    "\n",
    "results = {\n",
    "    'run_id':             f\"envis_v2_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
    "    'model_version':      'v2',\n",
    "    'completed':          datetime.now().isoformat(),\n",
    "    'epochs_trained':     len(training_log),\n",
    "    'best_epoch':         ckpt['epoch'],\n",
    "    'v2_improvements': [\n",
    "        'Unfrozen last 3 FinBERT layers + differential LR',\n",
    "        'Unified distress/sub-indicator 4-class head',\n",
    "        'Log1p timing delay + Huber loss',\n",
    "        'Class-weighted CE for framing/urgency/distress',\n",
    "        'BCEWithLogitsLoss + pos_weight for tension/goal_risk',\n",
    "        'Cross-attention fusion',\n",
    "        'Residual prediction heads',\n",
    "        'Mixed precision fp16 + gradient accumulation',\n",
    "        'Reduced MAX_TEXT=128, MAX_TRANS=20',\n",
    "    ],\n",
    "    'config':             cfg.__dict__,\n",
    "    'test_metrics':       {k: round(v, 4) if isinstance(v, float) else v for k, v in test_m.items()},\n",
    "    'distress_threshold': round(best_thr, 3),\n",
    "    'confusion_matrices': {\n",
    "        'distress_4class': confusion_matrix(test_L['distress_class'], test_P['distress_class']).tolist(),\n",
    "        'distress_binary': confusion_matrix(d_bin_true, d_bin_pred).tolist(),\n",
    "        'framing': confusion_matrix(test_L['framing'], test_P['framing']).tolist(),\n",
    "    },\n",
    "    'training_log':       training_log,\n",
    "}\n",
    "with open('evaluation_results_v2.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"  best_model_v2.pt            ({os.path.getsize('best_model_v2.pt')/1e6:.1f} MB)\")\n",
    "print(f\"  training_log_v2.csv         ({len(training_log)} epochs)\")\n",
    "print(f\"  evaluation_results_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('best_model_v2.pt')\n",
    "files.download('training_log_v2.csv')\n",
    "files.download('evaluation_results_v2.json')"
   ]
  }
 ]
}